# ğŸ¨ **Prompt Templates â€” LLMOps StudyBuddy**

This branch introduces the **first prompt templates** for the **LLMOps StudyBuddy** project.
It adds structured **LangChain `PromptTemplate` objects** used to generate:

* Multiple-choice questions (MCQs)
* Fill-in-the-blank questions

These templates instruct the LLM to return **strict JSON output** compatible with the projectâ€™s Pydantic question schemas.

## ğŸ—‚ï¸ **Updated Project Structure**

Only the **new folder and file** added in this branch are annotated:

```text
LLMOPS-STUDY-BUDDY/
â”œâ”€â”€ .venv/
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ llmops_study_buddy.egg-info/
â”œâ”€â”€ manifests/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ uv.lock
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ templates.py    # ğŸ¨ Prompt templates for MCQ + fill-in-the-blank generation
â””â”€â”€ README.md
```

## ğŸ§  **What This Branch Adds**

### ğŸ¨ `templates.py`

This module defines two reusable `PromptTemplate` objects:

* `mcq_prompt_template`

  * Generates a structured MCQ about a given topic and difficulty
  * Returns JSON with: `"question"`, `"options"`, `"correct_answer"`
  * Ensures exactly 4 options
  * Fully aligned with the `MCQQuestion` Pydantic schema

* `fill_blank_prompt_template`

  * Generates a fill-in-the-blank question containing `"_____"`
  * Returns JSON with: `"question"` and `"answer"`
  * Compatible with the `FillBlankQuestion` schema

Both templates enforce **strict formatting**, enabling reliable downstream validation and processing.

## ğŸ§ª **Example Usage**

```python
from prompts.templates import mcq_prompt_template, fill_blank_prompt_template

prompt = mcq_prompt_template.format(topic="machine learning", difficulty="medium")
print(prompt)

prompt2 = fill_blank_prompt_template.format(topic="calculus", difficulty="easy")
print(prompt2)
```

These templates can be passed directly into an LLM chain or wrapped by a higher-level service.

## âœ… **In Summary**

This branch:

* Adds a dedicated **`prompts/`** folder
* Provides **structured LangChain prompt templates** for MCQ and fill-blank generation
* Ensures all question generation follows a **strict JSON schema**
* Builds the foundation for future components such as LLM pipelines, tutoring agents, and evaluation modules